First I handle any edge cases, such as inputs like 'None' or non-strings, returning False for those instances.  Then, I use dictionaries to store the character counts of each letter in the words.  I chose this data structure because it has quick lookups.  Last, I check to make sure there are enough letters in string 's' for the counts of each letter in 't' such that t is an anagram of a substring of 's'.  I converted the character lists to sets, just in case the character lists are long.  This should help time efficiency somewhat.  The space complexity is O(len(s) + len(t)) (both space and time complexity are the same for worst, best, and average cases) since we are allocating new lists for both of the strings, and the time complexity is O(len(s) + len(t)) since we are going through each character of both strings.